## 一、需求

实时收集服务器日志同一存储到中心系统，并对日志建立索引，通过搜索即可快速定位找到对应日志，通过提供web界面实现日志检索与展示。

要求：日志量大，实现准实时收集，延迟控制在分钟级别，能够支持水平扩展。

### 业界方案

#### ELK

AppServer => LogstashAgent => ElasticSearchCluster => KibanaServer => Browser

##### 存在的问题

- 运维成本高，没增加一个日志收集项，都需要手动修改配置。
- ~~监控缺失、无法准确获取logstash的状态。~~
- 无法定制化开发与维护。

## 二、系统架构

![](.\Images\日志收集项目系统架构.png)

组件：

- Log Agent（生产者）：日志收集客户端，用于收集服务器上的日志。

- Kafka：高吞吐量的分布式队列。
- ElasticSearch：开源搜索引擎，提供HTTP RESTful的web接口。
- Kibana：开源的ES数据分析和可视化工具。

- tranfer（消费者）。

- etcd：配置管理，热加载（web界面实现）。

- Hadoop：分布式计算框架，大数据分布式处理平台。
- Storm：分布式实时计算系统。

### 技术栈

- 服务端agent开发。
- 后端服务组件开发。
- Kafka和zookeeper的使用。
- ElasticSearch和Kibana的使用。
- etcd的使用。

## 三、Kafka

前提：NSQ。

### 3.1 消息队列通信模型

#### 点对点模式

一对一，一条消息只能被消费一次，不存在重复消费。

#### 发布/订阅（topic）

一对多，消息生产者将消息发布到topic中，同时有多个消费者订阅（消费）该消息；与点对点相比，发布到topic的消息会被所有订阅者消费。

### 3.2 Kafaka简介

分布式数据流平台，可单机部署也可集群部署，提供发布/订阅功能，使用者可发送数据到Kafka中，也可从Kafka中读取数据；Kafka具有高吞吐、低延迟、高容错的特点。

### 3.3 Kafaka架构

Procuder => Kafaka Cluster（Broker-0、Broker-1...） => Consumer（Concumer Group A...）

- Procuder：生产者，消息入口。

- Kafka cluster：kafka集群，一台或多台服务器。
  - Broker：部署了Kafka实例的服务器节点，集群内编号唯一。
  - Topic：消息主题（分类），每个Broker可创建多个topic。
  - Partition：Topic的分区，用于负载，提高吞吐量，分区数据不重复。
  - Replication：分区副本，主分区故障时使用；副本默认数量10，数量不能大于Broker数量。
- Consumer：消费者，消息出口。
  -  Consumer Group：由多个消费者组成；同一个分区的数据只能被消费者组中的某一个消费者消费，同一个消费者组中的消费者可以消费同一个topic下不同分区的数据。

#### 工作流程

![](.\Images\Kafka工作流程.png)

说明：

1. 生产者从Kafka集群获取分区leader信息。
2. 生产者将消息发送到leader。
3. leader将消息写入本地磁盘。
4. follower从leader拉取消息数据。
5. follower将消息写入本地磁盘后向leader发送ACK。
6. leader收到所有follower的ACK后向生产者发送ACK。

#### 选择partition的原则

原则如下：

1. 写入时可以指定`partition`。
2. 未指定`partition`时，如果设置了`key`，则`hash`计算对应`partition`。
3. 未指定`partition`且未设置`key`时，使用轮询方式（按时间段）。

#### ACK应答机制

`procuder`在向Kafka写入消息时，可以设置参数来确认是否Kafka已接收到数据，参数取值为`0`、`1`、`all`。

- `0`：无需确认，安全性低、效率高。
- `1`：只确认`leader`已接收。
- `all`：确认`leader`已接收且`follower`已完成备份。

注：若向不存在的topic写数据，kafka将自动创建topic，partition和replication数量默认都为1.

#### Topic和数据日志

`topic`是同一类别的消息记录集合，一个主题通常有多个订阅者；对于每个`topic`，Kafka维护一个分区数据日志文件。每个`partition`都是一个有序并且不可变的消息记录集合，新消息写入时追加到`partition`末尾；在每个`partition`中，每条消息都被有序分配一个唯一标识`offset`，即偏移量。Kakfa只保证同一分区内的消息是有序的。Kafka可配置保留期限，过期时数据被清空。

#### Partition结构

Partition在服务器上的表现形式为文件夹，每个`partition`文件夹下有多组`segment`文件，每组`segment`文件包含`.index`文件、`.log`文件、`.timeindex`文件，其中`.log`文件用于存储消息，`.index`和`.timeindex`文件为索引文件，用于检索消息。

#### 消费数据

总结：

- 同一个分区的数据只能被消费者组中的某一个消费者实例消费。
- 一个消费者实例可以消费不同分区中的数据。

### 3.4 使用场景

#### 消息队列

跨进程通信、上下游消息传递、解耦。

#### 追踪网站活动

对网站活动进行追踪，将不同活动放入不同主题，供后续实时计算、实时监控等程序使用，也可导入数据仓库进行后续离线处理和生成报表。

#### Metrics

传输监控数据：聚合分布式应用程序的统计数据，将数据集中后进行同一的分析和展示。

##### 日志聚合

### 3.6 安装

#### 安装JDK

略。

#### 安装zookeeper

服务注册发现：调用方调用前先到注册中心查询可调用的服务。

下载地址：http://www.apache.org/dyn/closer.cgi/zookeeper/

#### 安装kafka

下载地址：http://kafka.apache.org/downloads（3.0.0版本有坑，使用2.8.1）

修改配置：./config/server.properties

```properties
# broker ID
broker.id=0
# 存储目录
log.dirs=D:/ProgramData/kafka-logs
# 分区数量
num.partitions=1
# zookeeper
zookeeper.connect=localhost:2181
```

修改配置：./config/zookeeper.properties

```properties
dataDir=D:/ProgramData/zookeeper-data
```

启动zookeeper（kafka自带）：

```powershell
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties
```

启动kafka：

```powershell
.\bin\windows\kafka-server-start.bat .\config\server.properties
```

启动kafka客户端：

```bash
.\bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic web_log --from-beginning
```

## 四、Etcd

### 4.1 etcd简介

Go语言开发的高可用的分布式K-V存储系统，可用于配置共享和服务的注册和发现。类似于`zookeeper`和`consul`。特点如下：

- 完全复制：集群的每个节点都可使用完整的存档。
- 高可用性：避免硬件单点故障或网络问题。
- 一致性：每次读写都返回跨多主机的最新写入。
- 简单：定义良好、面向用户的API（gRPC）。
- 安全：实现了带有可选功能的客户端身份验证的自动化TLS。
- 快速：每秒10000次写入的基准速度。
- 可靠：使用**Raft算法**实现强一致、高可用的服务存储目录。

### 4.2 etcd应用场景

#### 服务发现

查找集群中可用的服务。

#### 配置中心

应用在启动时主动从etcd获取配置信息，同时在etcd节点上注册一个Watcher并等待，以后每次配置更新时，etcd都会通知订阅者，以达到获取最新配置信息的目录。

#### 分布式锁

Etcd使用Raft算法实现了强一致性，故全局数据一致，易于实现分布式锁。锁服务的两种使用方式，一是保持独占，二是控制时序。

- 保持独占：所有获取锁的用户中只有一个可得到，etcd实现了原子操作的API。
- 控制时序：所有需要获取锁的用户都将被安排执行，但锁的顺序全局唯一（确定执行顺序）。

### 4.3 zookeeper的缺点

缺点：

- 部署维护复杂。
- Java编写~~（垃圾）~~，依赖过多。
- 发展缓慢。

### 4.4 etcd安装

官网：https://etcd.io/

下载地址：https://github.com/etcd-io/etcd/releases/download/v3.3.13/etcd-v3.3.13-windows-amd64.zip

### 4.5 etcd使用

#### 启动服务端

```
.\etcd.exe
```

#### 设置API版本

```
set ETCDCTL_API=3
```

#### 客户端：设置K-V

```
.\etcdctl.exe --endpoints=http://127.0.0.1:2379 put name "okarin"
```

#### 客户端：获取K-V

```
.\etcdctl.exe --endpoints=http://127.0.0.1:2379 get name
```

### 4.6 etcd集群搭建

https://www.cnblogs.com/51wansheng/p/10234036.html

### 4.7 go语言操作etcd

安装：

```powershell
go get go.etcd.io/etcd/clientv3
# go mod edit -replace github.com/coreos/bbolt@v1.3.4=go.etcd.io/bbolt@v1.3.4
```

可能出现的问题：http://wearygods.online/articles/2020/09/17/1600327573429.html

```
replace github.com/coreos/bbolt v1.3.4 => go.etcd.io/bbolt v1.3.4
replace google.golang.org/grpc => google.golang.org/grpc v1.26.0
```

示例：

```go
package main

import (
	"context"
	"fmt"
	"time"

	"go.etcd.io/etcd/clientv3"
)

func main() {
	client, err := clientv3.New(clientv3.Config{
		Endpoints:   []string{"127.0.0.1:2379"},
		DialTimeout: time.Second * 5,
	})
	if err != nil {
		fmt.Printf("connect to etcd failed, err:%v\n", err)
		return
	}
	defer client.Close()

	// put
	ctx, cancel := context.WithTimeout(context.Background(), time.Second*1)
	_, err = client.Put(ctx, "group", "LAB")
	if err != nil {
		fmt.Printf("put to etcd failed, err:%v\n", err)
		return
	}
	cancel()

	// get
	ctx, cancel = context.WithTimeout(context.Background(), time.Second*1)
	rsp, err := client.Get(ctx, "group")
	if err != nil {
		fmt.Printf("get from etcd failed, err:%v\n", err)
		return
	}

	for _, kv := range rsp.Kvs {
		fmt.Printf("key:%s value:%s\n", kv.Key, kv.Value)
	}
	cancel()
}
```

### 4.8 watch

监控。

```go
package main

import (
	"context"
	"fmt"
	"time"

	"go.etcd.io/etcd/clientv3"
)

func main() {
	client, err := clientv3.New(clientv3.Config{
		Endpoints:   []string{"127.0.0.1:2379"},
		DialTimeout: time.Second * 5,
	})
	if err != nil {
		fmt.Printf("connect to etcd failed, err:%v\n", err)
		return
	}
	defer client.Close()

	// watch
	watchCh := client.Watch(context.Background(), "group")
	for rsp := range watchCh {
		for _, event := range rsp.Events {
			fmt.Printf("type:%s key:%s value:%s\n", event.Type, event.Kv.Key, event.Kv.Value)
		}
	}
}
```

## 五、准备工作

### 4.1 使用sarama向kafka发送消息

下载sarama：

```powershell
go get github.com/Shopify/sarama
```

示例：

```go
package main

import (
	"fmt"

	"github.com/Shopify/sarama"
)

func main() {

	// 1.生产者配置
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll          // ACK
	config.Producer.Partitioner = sarama.NewRandomPartitioner // 分区
	config.Producer.Return.Successes = true                   // 交付成功消息

	// 2.连接kafka
	client, err := sarama.NewSyncProducer([]string{"127.0.0.1:9092"}, config)
	if err != nil {
		fmt.Println("producer closed, err:", err)
		return
	}
	defer func(client sarama.SyncProducer) {
		err := client.Close()
		if err != nil {
			fmt.Println("client close failed, err:", err)
		}
	}(client)

	// 3.封装消息
	msg := &sarama.ProducerMessage{
		Topic: "test",
		Value: sarama.StringEncoder("FIRST TEST"),
	}

	// 4.发送消息
	pid, offset, err := client.SendMessage(msg)
	if err != nil {
		fmt.Println("send msg failed, err:", err)
		return
	}
	fmt.Printf("pid:%v offset:%v\n", pid, offset)
}
```

消费消息：

```powershell
.\bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic test --from-beginning
```

### 4.2 使用tailf包读取日志文件

示例：

```go
package main

import (
	"fmt"
	"github.com/hpcloud/tail"
)

func main(){
	filename := `./xx.log`
	config := tail.Config{
		Location:  &tail.SeekInfo{
			Offset: 0,
			Whence: 2,
		},
		ReOpen:    true,
		MustExist: false,
		Poll:      true,
		Follow:    true,
	}

	//打开文件读取数据
	file, err := tail.TailFile(filename, config)
	if err != nil {
		fmt.Printf("tail %s failed, err:%v\n\n", filename, err)
		return
	}

	var(
		msg *tail.Line
		ok bool
	)

	for {
		msg, ok = <- file.Lines
		if !ok {
			fmt.Printf("tail file close reopen, filename:%s\n", file.Filename)
			break
		}
		fmt.Printf("msg:%s", msg.Text)
	}
}
```

### 4.3 使用sarama从kafka读取消息





## 六、日志收集agent开发

### 配置文件版

梳理：

- 使用`ini`包读取配置。
- 使用`tailf`包读取日志并存入`chan`。
- 使用`sarema`包操作kafka，从`chan`读取日志并发往`kafka`。
- 使用`logrus`打印日志。
- 使用方法封装对外部包提供的变量。

### etcd版

配置多个topic：

```json
[
    {
        "path": "D:/ProgramData/LogAgent/logs/s4.log",
        "topic": "s4_log"
    },
    {
        "path": "D:/ProgramData/LogAgent/logs/web.log",
        "topic": "web_log"
    }
]
```

压缩后：

```json
[{"path":"D:/ProgramData/LogAgent/logs/s4.log","topic":"s4_log"},{"path":"D:/ProgramData/LogAgent/logs/web.log","topic":"web_log"}]
```

思路：

- config模块在etcd配置项增加日志Key字段。
- main函数根据Key从etcd模块读取对应的配置信息。
- tailfile模块根据配置信息启动任务。
- 监控etcd中Key变化。







































